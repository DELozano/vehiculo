# %% [markdown]
# # Regresion Lineal 

# %%
#Importamos las librerias 
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# %% [markdown]
# # Paso 1 (análisis exploratorio)

# %%
# 1. Cargar los datos 

vh = pd.read_csv("C:/Users/ASUS/OneDrive/Escritorio/V4/Car.csv")

# %%
# 2. Mostrar las primeras 10 filas para conocer la estructura del dataset
print("Primeras filas del dataset:")
print(vh.head(10))

# %%
# 3. Información general del dataset
print("\nInformación del dataset:")
print(vh.info())

# %% [markdown]
# Explicación de las variables:
# 
# Make: Marca del vehículo (ej. Honda, Toyota)
# 
# Model: Modelo específico del vehículo
# 
# Price: Precio (nuestra variable objetivo a predecir)
# 
# Year: Año de fabricación
# 
# Kilometer: Kilometraje del vehículo
# 
# Fuel Type: Tipo de combustible (Petrol, Diesel, CNG, etc.)
# 
# Transmission: Tipo de transmisión (Manual, Automática)
# 
# Location: Ciudad donde se vende el vehículo
# 
# Color: Color del vehículo
# 
# Owner: Número de dueños previos
# 
# Seller Type: Tipo de vendedor (Individual, Corporativo)
# 
# Engine: Tamaño del motor en cc
# 
# Max Power: Potencia máxima en bhp
# 
# Max Torque: Par máximo en Nm
# 
# Drivetrain: Tracción (FWD, RWD, AWD)
# 
# Length, Width, Height: Dimensiones del vehículo
# 
# Seating Capacity: Capacidad de pasajeros
# 
# Fuel Tank Capacity: Capacidad del tanque de combustible

# %%
# 4. Estadísticas descriptivas para columnas numéricas
print("\nEstadísticas descriptivas:")
print(vh.describe())


# %% [markdown]
# # Paso 2: Preprocesamiento de los datos

# %%
# 1. Eliminar duplicados
vh.drop_duplicates(inplace=True)

# %%
# 2. Identificar valores faltantes
print("\nValores faltantes en cada columna:")
print(vh.isnull().sum())

# %%
# 3. Rellenar valores faltantes con la media de cada columna
vh.fillna(vh.mean(numeric_only=True), inplace=True)


# %%
# 4. Verificar que ya no hay valores faltantes
print("Valores faltantes después de rellenar:")
print(vh.isnull().sum())

# %%
# 5. Rellenar valores no numéricos con la moda (el valor más común)
columnas_no_numericas = vh.select_dtypes(include='object').columns

for col in columnas_no_numericas:
    if vh[col].isnull().sum() > 0:
        moda = vh[col].mode()[0]
        vh[col] = vh[col].fillna(moda)
        print(f"Columna '{col}' rellenada con la moda: {moda}")


# %%
print("Verificar si hay valores faltantes: ")
print(vh.isnull().sum())

# %% [markdown]
# Se puede identificar que no hay valores faltantes

# %%
# 6. Codificar variables categóricas (conversión texto a números)
label_encoder = LabelEncoder()
for col in columnas_no_numericas:
    vh[col] = label_encoder.fit_transform(vh[col])

# %%
# 7. Verificar datos limpios
print("\nRevisión final de valores faltantes:")
print(vh.isnull().sum())

print("\nTipos de datos después del preprocesamiento:")
print(vh.dtypes)


# %%
# 8. Mostrar una muestra de los datos procesados
print("\nVista previa de los datos ya preprocesados:")
print(vh.head())

# %%
plt.rcParams['figure.figsize'] = (12, 6)

# %%
# 6. Histograma de precios
plt.figure()
sns.histplot(vh["Price"], kde=True, bins=30, color='skyblue')
plt.title("Distribución del Precio de los Vehículos")
plt.xlabel("Precio")
plt.ylabel("Cantidad de Vehículos")
plt.grid(True)
plt.tight_layout()
plt.show()

# %%
import seaborn as sns
import matplotlib.pyplot as plt

# 8. Gráfico de conteo de la variable 'Transmission' con 'Fuel Type' como hue
plt.figure(figsize=(10, 6))
sns.countplot(data=vh, x="Transmission", hue="Fuel Type", palette='Set2')
plt.title('Conteo de Transmisiones por Tipo de Combustible')
plt.xlabel('Transmisión')
plt.ylabel('Conteo')
plt.legend(title='Tipo de Combustible')
plt.show()


# %%
# 9. Box plot para ver valores atípicos en el precio
plt.figure()
sns.boxplot(data=vh, y="Price", color='lightcoral')
plt.title("Boxplot del Precio de los Vehículos (Detección de Atípicos)")
plt.ylabel("Precio")
plt.tight_layout()
plt.show()

# %% [markdown]
# # PASO 3: Selección de características relevantes

# %%
from sklearn.feature_selection import SelectKBest, f_regression

# Seleccionar las mejores características
selector = SelectKBest(score_func=f_regression, k=10)  # Selecciona las 10 más relevantes
X_selected = selector.fit_transform(X, y)

# Guardar nombres de las columnas seleccionadas
selected_columns = X.columns[selector.get_support()]
X = X[selected_columns]


# %% [markdown]
# # PASO 4: División en Train y Test

# %%
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


# %% [markdown]
# # PASO 5: Entrenamiento del modelo

# %%
from sklearn.ensemble import RandomForestRegressor

# Crear y entrenar el modelo
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)


# %% [markdown]
# # PASO 6: Evaluación del modelo en test

# %%
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, root_mean_squared_error

# Crear y entrenar el modelo (suponiendo que ya lo hayas hecho)

# Hacer predicciones en el conjunto de prueba
y_test_pred = model.predict(X_test)

# Evaluar el desempeño en el conjunto de prueba con la nueva función RMSE
test_rmse = root_mean_squared_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f"\n📊 Desempeño en conjunto de prueba:")
print(f"RMSE: {test_rmse:.2f}")
print(f"R²: {test_r2:.2f}")


# %% [markdown]
# #          Graficos (paso 6 y paso 7)

# %% [markdown]
# # 1. Gráfico de predicción vs valor real

# %%
import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred, alpha=0.5, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # línea ideal
plt.xlabel('Precio Real')
plt.ylabel('Precio Predicho')
plt.title('Precio Real vs Predicho')  # Eliminar emoji para evitar la advertencia
plt.grid(True)
plt.show()



# %% [markdown]
# # 2. Importancia de características

# %%
import pandas as pd

# Obtener importancias
importancias = model.feature_importances_

# Crear DataFrame con nombres y valores
importancia_df = pd.DataFrame({
    'Característica': X.columns,
    'Importancia': importancias
}).sort_values(by='Importancia', ascending=False)

# Graficar
plt.figure(figsize=(10,6))
plt.barh(importancia_df['Característica'], importancia_df['Importancia'], color='green')
plt.xlabel('Importancia')
plt.title('Importancia de Características')
plt.gca().invert_yaxis()
plt.grid(True)
plt.show()


# %% [markdown]
# # 3. Gráfico de errores residuales

# %%
residuos = y_test - y_pred

plt.figure(figsize=(8,6))
plt.hist(residuos, bins=30, color='purple', edgecolor='black')
plt.title(' Distribución de errores residuales')
plt.xlabel('Error')
plt.ylabel('Frecuencia')
plt.grid(True)
plt.show()


# %% [markdown]
# # Interpretación y análisis de resultados

# %% [markdown]
# 1. Precio Real vs. Precio Predicho
# Interpretación:
# El gráfico que compara el precio real con el predicho sigue siendo una herramienta valiosa para observar qué tan cerca están los puntos de la línea ideal (en rojo). Si el modelo ha mejorado, los puntos deberían alinearse más estrechamente con la línea diagonal, lo que indica una mayor precisión en las predicciones.
# 
# Conclusión:
# El modelo muestra una mejora al acercar las predicciones al valor real del precio, lo que refleja una mayor exactitud en sus estimaciones.

# %% [markdown]
# 2. Importancia de las Características
# Interpretación:
# Cuando una o varias características principales cambian su nivel de relevancia, esto puede indicar una selección de variables más adecuada. Asimismo, un aumento en el valor de R² sugiere que el modelo está captando mejor las variables que verdaderamente afectan el precio.
# 
# Conclusión:
# Gracias a un R² más alto, el modelo demuestra una mayor capacidad para identificar con precisión las características más influyentes en el precio del automóvil.

# %% [markdown]
# 3. Distribución de Errores Residuales
# Interpretación:
# El histograma de los errores residuales debería reflejar una menor dispersión, con valores más próximos a cero y una distribución más equilibrada. Si el modelo ha mejorado, los errores tenderán a concentrarse alrededor de cero y mostrarán menos sesgo.
# 
# Conclusión:
# Con un R² de 0.71, se evidencia que los errores están mejor controlados y dentro de un rango más estrecho. Esto sugiere que el modelo está realizando predicciones más precisas y sin desviaciones significativas.

# %% [markdown]
# Evaluación general del modelo 
# 
# RMSE en entrenamiento: 1.61 millones
# 
# R² en entrenamiento: 0.53
# 
# RMSE en prueba: 1.42 millones
# 
# R² en prueba: 0.71
# 
# Análisis:
# Con un R² de 0.71 en los datos de prueba, el modelo es capaz de explicar más del 70% de la variabilidad en el precio del automóvil. Esto representa una mejora notable respecto a los resultados previos. No obstante, todavía hay espacio para optimizar el desempeño, ya que el modelo no alcanza una precisión total (siendo 1 el valor ideal de R²). Para seguir mejorando, se podrían considerar modelos más avanzados o aplicar técnicas de ajuste de hiperparámetros.


